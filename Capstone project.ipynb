# Importing the libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
# Importing the dataset
df = pd.read_csv('Automobile_data.csv')
df.head()
# finding unique values in dataset columns
for i in df.columns:
    print(i, df[i].unique())
# Data Cleaning
# finding missing values in dataset
for col in df.columns:
    for i in df.index:
        if df.loc[i, col] == '?':
            print(col)
# fixing ? in normalized _ losses, no of doors, bore, stroke, horsepower, peak rpm, price

col_for_change = ['normalized-losses','num-of-doors','bore','stroke','horsepower','peak-rpm','price']

for col in col_for_change:
    for i in df.index:
        if df.loc[i, col] == '?':
            df[col] = df[col].replace('?', np.nan)

for col in col_for_change:
    if col == 'num-of-doors':
        m = df[col].mode()
        df[col].fillna(m[0],inplace=True)
    else:
        df[col] = df[col].astype(float)
        m = df[col].median()
        df[col].fillna(m,inplace=True)

df.isnull().sum()
df.info()
original_df = df
original_df
# coverting into numerical
for col in df.columns:
    if df[col].dtypes == object:
        df[f'{col}_encoded']=df[col].astype('category').cat.codes

# removing non numericals
for col in df.columns:
    if df[col].dtypes == object:
        df.drop(col, axis=1,inplace=True)
df
# Finding correlation between the features
c = []
cor = []
for i in range(0,25):
    corr=df[df.columns[i]].corr(df['price'])
    c.append(df.columns[i])
    cor.append(corr)
print(c)
print(cor)
plt.figure(figsize=(18, 18))
sns.heatmap(data=df.corr(), annot=True)
plt.title('Correlation between features in dataframe')
plt.show()
# Converting coorelations of features into a dataframe for better visualization
corr_df = pd.DataFrame({'Columns' : c, 'Correlation' : cor})
corr_df.reset_index
# Sorted the correlations of features for finding best correlated features
sorted_corr_col = corr_df.sort_values(by='Correlation', ascending=False)
sorted_corr_col.drop(15,axis=0,inplace=True)
sorted_corr_col
# Implementing Multiple Linear Regression for prediction 

X = df[['engine-size','curb-weight','horsepower','width']]
y = df['price']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a Multiple Linear Regression model
model = LinearRegression()

# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Model Evaluation
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")

# Finding MSE and R2 with increasing different features for more accuracy

MSE=[]
R2=[]
N=[]
for i in range(2,26):
    X = df[sorted_corr_col.iloc[0:i]['Columns']]
    # X = df[['engine-size','curb-weight','horsepower','width']]
    y = df['price']
    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # Create a Multiple Linear Regression model
    model = LinearRegression()
    
    # Train the model
    model.fit(X_train, y_train)
    
    # Make predictions on the test set
    y_pred = model.predict(X_test)
    
    # Model Evaluation
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    print(i)
    print(f"Mean Squared Error: {mse}")
    print(f"R-squared: {r2}")
    
    MSE.append(mse)
    R2.append(r2)
    N.append(i)
# Converting MSE and R2 of features into a dataframe for better visualization
line_df = pd.DataFrame({'No_of_Columns' : N, 'MSE' : MSE, 'R2' : R2})
line_df
#  Ploting a line plot for visualizing MSE with different no of columns
sns.lineplot(x=line_df['No_of_Columns'], y=line_df['MSE'])
plt.title('No of columns vs MSE')
plt.show()
#  Ploting a line plot for visualizing MSE with different no of columns
sns.lineplot(x=line_df['No_of_Columns'], y=line_df['R2'])
plt.title('No of columns vs R2')
plt.show()
# As from ploting we can say R2 is high when we take 8 columns for predicting model so it gives high accuracy

X = df[sorted_corr_col.iloc[0:8]['Columns']]
y = df['price']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a Multiple Linear Regression model
model = LinearRegression()

# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Model Evaluation
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")
# engine-size, curb-weight, horsepower, width, length, wheel-base, drive-wheels_encoded, bore, engine-location_encoded
# Above are the 8 features used for prediction for high accuracy
# Predicting price of car based on features 
X_test=[[152, 2823, 154, 65.5, 171.2, 94.5, 2, 2.68]]
y_pred = model.predict(X_test)
y_pred
